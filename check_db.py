# check_db.py
import os
import sqlite3
import json
import argparse
import pprint

import chromadb
from dotenv import load_dotenv

# --- RAG í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì¶”ê°€ ì„í¬íŠ¸ ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# --- ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---
load_dotenv()
CHROMA_DB_DIR = os.getenv("CHROMA_DB_DIR", "./chroma_db")
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "school_announcements")
SQLITE_CACHE_DB = "./cache/embeddings.sqlite"

def check_chromadb(limit: int):
    """ChromaDBì— ì €ì¥ëœ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    print("=" * 50)
    print(f"ğŸ” ChromaDB í™•ì¸ ì¤‘... (ê²½ë¡œ: {CHROMA_DB_DIR})")
    print("=" * 50)

    if not os.path.exists(CHROMA_DB_DIR):
        print(f"ì˜¤ë¥˜: ChromaDB ë””ë ‰í† ë¦¬('{CHROMA_DB_DIR}')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("'indexer.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return

    try:
        client = chromadb.PersistentClient(path=CHROMA_DB_DIR)
        collection = client.get_collection(name=COLLECTION_NAME)

        total_count = collection.count()
        print(f"âœ… ì´ {total_count}ê°œì˜ ë²¡í„°(ì²­í¬)ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        if total_count == 0:
            return

        print(f"\nğŸ“„ ìƒ˜í”Œ ë°ì´í„° {min(limit, total_count)}ê°œ ë¯¸ë¦¬ë³´ê¸°:")
        print("-" * 20)

        # includeì— "embeddings"ë¥¼ ì¶”ê°€í•˜ë©´ ë²¡í„° ê°’ë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        data = collection.get(limit=limit, include=["metadatas", "documents"])

        for i in range(len(data["ids"])):
            print(f"\n[{i+1}] ID: {data['ids'][i]}")
            print("  [ë©”íƒ€ë°ì´í„°]:")
            pprint.pprint(data['metadatas'][i], indent=4, width=100)
            print("  [ë‚´ìš© (ì• 100ì)]:")
            document_preview = data['documents'][i][:100].replace('\n', ' ') + "..."
            print(f"    '{document_preview}'")
            print("-" * 20)

    except Exception as e:
        print(f"ChromaDB í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")


def check_sqlite_cache(limit: int):
    """SQLite ì„ë² ë”© ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    print("\n" + "=" * 50)
    print(f"ğŸ” SQLite ìºì‹œ DB í™•ì¸ ì¤‘... (ê²½ë¡œ: {SQLITE_CACHE_DB})")
    print("=" * 50)

    if not os.path.exists(SQLITE_CACHE_DB):
        print(f"ì˜¤ë¥˜: SQLite ìºì‹œ íŒŒì¼('{SQLITE_CACHE_DB}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        conn = sqlite3.connect(SQLITE_CACHE_DB)
        cursor = conn.cursor()

        # ì „ì²´ ê°œìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM emb")
        total_count = cursor.fetchone()[0]
        print(f"âœ… ì´ {total_count}ê°œì˜ ì„ë² ë”© ê²°ê³¼ê°€ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        if total_count == 0:
            conn.close()
            return

        print(f"\nğŸ“„ ìƒ˜í”Œ ë°ì´í„° {min(limit, total_count)}ê°œ ë¯¸ë¦¬ë³´ê¸°:")
        print("-" * 20)

        # ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        cursor.execute("SELECT k, v FROM emb LIMIT ?", (limit,))
        rows = cursor.fetchall()

        for i, (key, value) in enumerate(rows):
            vector = json.loads(value)
            vector_preview = str(vector[:3])[:-1] + ", ...]" # ë²¡í„° ì• 3ê°œë§Œ í‘œì‹œ
            print(f"\n[{i+1}] Key (SHA256): {key[:20]}...")
            print(f"  - Vector (size: {len(vector)}): {vector_preview}")

        conn.close()

    except Exception as e:
        print(f"SQLite ìºì‹œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def test_rag_query(query: str):
    """ì£¼ì–´ì§„ ì¿¼ë¦¬ë¡œ RAG íŒŒì´í”„ë¼ì¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\n" + "=" * 50)
    print(f"âš¡ RAG í…ŒìŠ¤íŠ¸ ì‹œì‘... (ì§ˆë¬¸: '{query}')")
    print("=" * 50)

    if not os.path.exists(CHROMA_DB_DIR):
        print(f"ì˜¤ë¥˜: ChromaDB ë””ë ‰í† ë¦¬('{CHROMA_DB_DIR}')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("'indexer.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return

    try:
        # 1. Vector DB ë¡œë“œ
        print("1. Vector DB ë¡œë“œ ì¤‘...")
        embeddings = OpenAIEmbeddings(model=os.getenv("EMBED_MODEL", "text-embedding-3-small"))
        vectordb = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)
        retriever = vectordb.as_retriever(search_kwargs={"k": 3})
        print("âœ… Vector DB ë¡œë“œ ì™„ë£Œ")

        # 2. LLM ë° Prompt ì„¤ì •
        print("2. LLM ë° Prompt ì„¤ì • ì¤‘...")
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        prompt_template = """
        ë‹¹ì‹ ì€ í•™êµ ê³µì§€ì‚¬í•­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        ë‹µë³€ì€ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
        1. ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ 'ë¬¸ë§¥' ì •ë³´ì—ë§Œ ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        2. ë‹µë³€ì´ ì–´ë–¤ ë¬¸ì„œì—ì„œ ë¹„ë¡¯ë˜ì—ˆëŠ”ì§€ 'ì¶œì²˜'ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
        3. ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        4. ë¬¸ë§¥ì—ì„œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, "ì£„ì†¡í•©ë‹ˆë‹¤, ì œê³µëœ ì •ë³´ ë‚´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

        [ë¬¸ë§¥]
        {context}

        [ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        """
        PROMPT = PromptTemplate(
            template=prompt_template, input_variables=["context", "question"]
        )
        print("âœ… LLM ë° Prompt ì„¤ì • ì™„ë£Œ")

        # 3. RetrievalQA ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
        print("3. RetrievalQA ì²´ì¸ ìƒì„± ë° ì‹¤í–‰ ì¤‘...")
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        response = qa_chain.invoke({"query": query})
        print("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")

        # 4. ê²°ê³¼ ì¶œë ¥
        print("\n" + "-" * 20)
        print("ğŸ¤– [ìƒì„±ëœ ë‹µë³€]:")
        print(response['result'])
        print("\n" + "-" * 20)
        print("ğŸ“š [ì°¸ê³ í•œ ë¬¸ì„œ]:")
        if response['source_documents']:
            for i, doc in enumerate(response['source_documents']):
                metadata = doc.metadata
                print(f"  [{i+1}] ì†ŒìŠ¤: {metadata.get('source', 'N/A')}")
                print(f"      - ì¹´í…Œê³ ë¦¬: {metadata.get('category', 'N/A')}")
                print(f"      - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: '{doc.page_content[:80].replace(chr(10), ' ')}...'")
        else:
            print("  ì°¸ê³ í•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("-" * 20)

    except Exception as e:
        print(f"\nRAG í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸ ë° RAG í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸")
    subparsers = parser.add_subparsers(dest="command", help="ì‹¤í–‰í•  ëª…ë ¹ì–´", required=True)

    # 'check' ëª…ë ¹ì–´: ê¸°ì¡´ DB í™•ì¸ ê¸°ëŠ¥
    parser_check = subparsers.add_parser("check", help="ë°ì´í„°ë² ì´ìŠ¤ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.")
    parser_check.add_argument(
        "--db", type=str, choices=["chroma", "sqlite", "all"], default="all",
        help="í™•ì¸í•  ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë¥˜ (chroma: ë²¡í„°DB, sqlite: ì„ë² ë”© ìºì‹œ, all: ë‘˜ ë‹¤)"
    )
    parser_check.add_argument("-n", "--limit", type=int, default=3, help="ë¯¸ë¦¬ë³´ê¸°ë¡œ ë³´ì—¬ì¤„ ë°ì´í„° ê°œìˆ˜")

    # 'query' ëª…ë ¹ì–´: RAG í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥
    parser_query = subparsers.add_parser("query", help="ê°„ë‹¨í•œ RAG í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    parser_query.add_argument("query_text", type=str, help="ì±—ë´‡ì—ê²Œ í•  ì§ˆë¬¸")

    args = parser.parse_args()

    if args.command == "check":
        if args.db in ["chroma", "all"]:
            check_chromadb(args.limit)
        if args.db in ["sqlite", "all"]:
            check_sqlite_cache(args.limit)
    elif args.command == "query":
        test_rag_query(args.query_text)